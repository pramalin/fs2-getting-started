<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <title>Getting Started with FS2</title>
        <link rel="stylesheet" href="./css/reveal.css">
        <link rel="stylesheet" href="./css/theme/beige.css" id="theme">
        <link rel="stylesheet" href="./css/highlight/atom-one-light.css">
        <link rel="stylesheet" href="./css/print/paper.css" type="text/css" media="print">


    </head>
    <body>

        <div class="reveal">
            <div class="slides"><section ><section data-markdown><script type="text/template">

>Getting started with FS2 

_Functional Streams for Scala_

### Agenda

- Motivation
- Pure Functional Programming
- IO Streams
- File IO Streams
- Q&A
</script></section><section data-markdown><script type="text/template">
### Bio
```
தொட்டனைத் தூறும் மணற்கேணி மாந்தர்க்குக் 
கற்றனைத் தூறும் அறிவு.
```
___
```txt
Like well flows high as it's dug,
humans gain knowledge as they learn more.

Thirukkural #396.
```

<aside class="notes"><ul>
<li>Senior developer for Citi</li>
<li>Facinated by FP.</li>
<li>Completed Machine Learning, Deep Learning Specilization and other courses. </li>
<li><a href="https://archive.org/details/tiruvalluvanayan00tiruuoft">https://archive.org/details/tiruvalluvanayan00tiruuoft</a></li>
<li>Remember - Ellis, Francis Whyte. John Pennycuick.</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">
### Motivation

- Scala: from better Java to FP
- Advent of Typelevel ecosystem
- Libraries based on FS2
</script></section><section data-markdown><script type="text/template">
### History

https://fs2.io/
 - v1.0.0  Oct  5, 2018

 (previously scalaz-stream)
 - v0.8.5 Oct 23, 2016 
 - v0.1   Oct 10, 2013 
 - Final chapter from Functional programming in Scala Book. </script></section></section><section ><section data-markdown><script type="text/template">
### Dependencies
  - <!-- .element: class="fragment" data-fragment-index="1"--> Cats Effect 
> <!-- .element: class="fragment" data-fragment-index="1" -->The IO Monad for Scala
  - <!-- .element: class="fragment" data-fragment-index="2" --> Cats
> <!-- .element: class="fragment" data-fragment-index="2" -->Lightweight, modular, and extensible library for functional programming
</script></section><section data-markdown><script type="text/template">
### REPL setup
[ammonite](http://ammonite.io/#Ammonite-REPL)
```sh
>java -jar ~/tools/ammonite/amm-2.12-1.6.2.jar

Welcome to the Ammonite Repl 1.6.2
(Scala 2.12.8 Java 1.8.0_181)
If you like Ammonite, please support our development at www.patreon.com/lihaoyi

@ interp.load.ivy("co.fs2" %% "fs2-core" % "1.0.2")

@ "hello, world!"
// res1: String = "hello, world!"
```</script></section><section data-markdown><script type="text/template">#### Mask verbose print
```scala
def disablePrettyPrintIO = repl.pprinter.update(repl.pprinter().copy(additionalHandlers = {
  case io: cats.effect.IO[_] => pprint.Tree.Literal("✨✨✨")
}))
disablePrettyPrintIO
def enablePrettyPrintIO = repl.pprinter.update(repl.pprinter().copy(additionalHandlers = PartialFunction.empty))
```
<aside class="notes"><ul>
<li>disable printing verbose internals</li>
</ul>
</aside></script></section></section><section ><section data-markdown><script type="text/template">### Pure

**Referential transparency**:
> Where one can replace an expression for its value, without changing the result

<aside class="notes"></aside></script></section><section data-markdown><script type="text/template">
### Side Effects

```scala
val expr = 123
// expr: Int = 123

(expr, expr)
// res1: (Int, Int) = (123, 123)

val expr = println("Hey!")
// Hey!

(expr, expr)
// res3: (Unit, Unit) = ((), ())
```
<!-- .element: class="fragment" --> **Not pure**</script></section><section data-markdown><script type="text/template">
### Side effects in concurrency

```scala
import scala.io.StdIn
import scala.concurrent.Future
import scala.concurrent.ExecutionContext.Implicits.global
import cats.syntax.apply._   // for mapN
import cats.instances.all._  // implicits

val read : Future[Int] = Future(StdIn.readInt)
// does not work as Future is eager and undeterministic
val result : Future[Int] = (read, read).mapN(_ + _)
```

<!-- .element: class="fragment" --> **Not pure**
</script></section></section><section ><section data-markdown><script type="text/template">
## Cats Effect 

**`IO[A]`** <!-- .element: class="fragment" -->

- <!-- .element: class="fragment" --> Produces one value, fails or never terminates
- <!-- .element: class="fragment" --> *Referentially transparent* (pure)
- <!-- .element: class="fragment" --> Compositional
- <!-- .element: class="fragment" --> Many algebras (monad,...)
</script></section><section data-markdown><script type="text/template">
### Managing effects
using IO

```scala 
import cats.effect.IO

IO(println("Hey!"))
// res13: IO[Unit] = Delay(...)
res13.unsafeRunSync
// Hey!

val n = IO.pure(10)
// n: IO[Int] = Pure(10)

n.unsafeRunSync
// res4: Int = 10

``` 
<aside class="notes"><ul>
<li>The operations are suspended and run on demand only </li>
</ul>
<p><!-- .element: class="fragment" --> <strong>Pure</strong></p>
</aside></script></section><section data-markdown><script type="text/template">
### Managing effects

```scala
def putStrLn(line: String): IO[Unit] =  IO {println(line)}
def f(a: IO[Unit], b: IO[Unit]): Unit = { 
  a.unsafeRunSync; b.unsafeRunSync
}

f(putStrLn("hi!"), putStrLn("hi!"))
// hi!
// hi!

val x = putStrLn("hi!")
f(x, x)
// hi!
// hi!
```
<aside class="notes"><ul>
<li>side effects issue is resolved.</li>
<li>IO encapsulates the description of effects and maintain RT</li>
</ul>
</aside></script></section></section><section ><section data-markdown><script type="text/template">### IO Monad 

```scala

 // trait Monad[F[_]] extends Functor[F] {
  def pure[A](a: => A): F[A] = ???
  def flatMap[A,B](ma: F[A])(f: A => F[B]): F[B] = ???

import cats.effect.IO

val t = IO.pure(42)
// t: IO[Int] = Pure(42)

t.map {i => i + 1}
// res4: IO[Int] = Map(Pure(42), ...)

res4.unsafeRunSync
// res5: Int = 43


```
<aside class="notes"><ul>
<li>pure and flatmap are the primitive combinators.</li>
<li>map is a derived combinator.</li>
<li>IO Monad have other methods to support concurrency, cancel, etc.</li>
<li>we&#39;ll see concurrency next.</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### for comprehension
sidebar
```scala
List(1, 2, 3).flatMap(n => List("a", "b").map(c => (n, c)))
// res10: List[(Int, String)] = List((1, "a"), (1, "b"), (2, "a"), (2, "b"), (3, "a"), (3, "b"))

for {
   n <- List(1, 2, 3)
   c <- List("a", "b")
 } yield (n, c)
// res11: List[(Int, String)] = List((1, "a"), (1, "b"), (2, "a"), (2, "b"), (3, "a"), (3, "b"))
```
<aside class="notes"><ul>
<li>for comprehension is syntactic sugar to manage flatMap and maps</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### IO Application
Pure hello world
```scala

  def putStrlLn(value: String) = IO(println(value))
  val readLn = IO(scala.io.StdIn.readLine)

  val hello = for {
    _ <- putStrlLn("What's your name?")
    n <- readLn
    _ <- putStrlLn(s"Hello, $n!")
  } yield ()

  hello.unsafeRunSync()
```</script></section><section data-markdown><script type="text/template">### IO Monad - concurrency 
main thread

```scala
import cats.effect.IO
import cats.effect.ContextShift
implicit val ioContextShift: ContextShift[IO] = IO.contextShift(scala.concurrent.ExecutionContext.Implicits.global)

val t = IO { println(s"Computing on ${Thread.currentThread.getName}..."); System.currentTimeMillis}
t.unsafeRunSync
// Computing on main...
// res12: Long = 1548213244359L

val t = IO.delay { println(s"Computing on ${Thread.currentThread.getName}..."); System.currentTimeMillis}
t.unsafeRunSync
// Computing on main...
// res14: Long = 1548213268629L


```

<aside class="notes"><ul>
<li>ContextShift implicit is essntial for concurrency</li>
<li>Displaying the thread name to validate</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### IO Monad - concurrency 
forked thread

```scala
t.start
//res7: IO[cats.effect.Fiber[IO, Long]] = Async(...

val fiber = res7.unsafeRunSync
// Computing on scala-execution-context-global-33...
// fiber: cats.effect.Fiber[IO, Long] = Tuple(
  Bind(Pure(Right(1548252366654L)),.. 

fiber.join.unsafeRunSync
// res9: Long = 1548252366654L

```

<aside class="notes"><ul>
<li>ContextShift implicit is essntial for concurrency</li>
<li>Displaying the thread name to validate</li>
</ul>
</aside></script></section></section><section  data-markdown><script type="text/template">
### Stream
(scala.collection)
```scala
Stream(1, 2, 3)
// res1: Stream[Int] = Stream(1, 2, 3)

Stream(1, 2, 3).map(_ + 1)
// res2: Stream[Int] = Stream(2, 3, 4)

Stream(1, 2, 3).map(_ + 1).map(_.toString)
// res3: Stream[String] = Stream("2", "3", "4")
```
<aside class="notes"><ul>
<li>Refresher collection Stream before IO Streams</li>
</ul>
</aside></script></section><section ><section data-markdown><script type="text/template">
## fs2 Streams

**`Stream[F[_], A]`** <!-- .element: class="fragment" -->

-  <!-- .element: class="fragment" --> emits `0...n ` values of type `A`, where `n` can be ∞ 
-  <!-- .element: class="fragment" --> While requesting effects in `F`
-  <!-- .element: class="fragment" --> `F` is normally `IO`

<aside class="notes"><ul>
<li>also pure, compositional, possesses algebras</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### FS2 Stream
-without effects
```scala
import fs2._

Stream(1, 2, 3)
// res2: Stream[Nothing, Int] = Stream(..)

Stream(1, 2, 3).map(_ + 1)
// res3: Stream[Nothing, Int] = Stream(..)

Stream(1, 2, 3).map(_ + 1).map(_.toString)
// res4: Stream[Nothing, String] = Stream(..)

Stream(1, 2, 3).flatMap { n => Stream.emit(List.fill(n)(n))}
// res5: Stream[Nothing, List[Int]] = Stream(..)
```</script></section><section data-markdown><script type="text/template">### Pure Stream
combinators - interleave and interperse.
```scala
val s = Stream(1, 2, 3)
// s: Stream[Nothing, Int] = Stream(..)
val t = Stream(4, 5, 6)
// t: Stream[Nothing, Int] = Stream(..)
val u = s interleave t
// u: Stream[Nothing, Int] = Stream(..)
u.toList
// res9: List[Int] = List(1, 4, 2, 5, 3, 6)

val s = Stream.range(0, 10)
// s: Stream[Nothing, Int] = Stream(..)
val t = s.intersperse(-42)
// t: Stream[Nothing, Int] = Stream(..)
t.toList
// res12: List[Int] = List(0, -42, 1, -42, 2, -42, 3, -42, 4, -42, 5, -42, 6, -42, 7, -42, 8, -42, 9)
```
</script></section><section data-markdown><script type="text/template">### Pure Stream
combinators - zip.
```scala
val s = Stream.range(0, 10)
// s: Stream[Nothing, Int] = Stream(..)
val t = Stream(1, 2, 3)
// t: Stream[Nothing, Int] = Stream(..)
s.zip(t3).toList
// res15: List[(Int, Int)] = List((0, 1), (1, 2), (2, 3))
```</script></section></section><section ><section data-markdown><script type="text/template">### IO Stream
```scala
interp.load.ivy("co.fs2" %% "fs2-core" % "1.0.2")
interp.load.ivy("co.fs2" %% "fs2-io" % "1.0.2")

import cats.effect.IO
import cats.effect.ContextShift
import fs2._

implicit val ioContextShift: ContextShift[IO] = IO.contextShift(scala.concurrent.ExecutionContext.Implicits.global)
// ioContextShift: ContextShift[IO] = cats.effect.internals.IOContextShift ...

val currentTime: IO[Long] = IO.delay {System.currentTimeMillis}
// currentTime: IO[Long] = Delay(...)
Stream.eval(currentTime)
// res7: Stream[IO, Long] = Stream(..)

```
<aside class="notes"><ul>
<li>notice the type of the stream created.</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### IO Stream
Infinite IO Stream
```scala
Stream.eval(currentTime).repeat.take(5).compile.toVector
// res8: IO[Vector[Long]] = Map( ...
res8.unsafeRunSync
// res9: Vector[Long] = Vector(1548292261803L, 1548292261848L, 1548292261848L, 1548292261848L, 1548292261848L)

Stream.repeatEval(currentTime).take(5).compile.toVector
// res10: IO[Vector[Long]] = Map(...
```
<aside class="notes"><ul>
<li>repeatEval is short</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### IO Stream
Combining with pure Streams
```scala
val s = Stream.range(0,8)
// s: Stream[Nothing, Int] = Stream(..)
s.zip(Stream.repeatEval(currentTime))
// res11: Stream[IO, (Int, Long)] = Stream(..)
@ res11.compile.toVector.unsafeRunSync
res12: Vector[(Int, Long)] = Vector(
  (0, 1548293081488L),
  (1, 1548293081490L),
  (2, 1548293081490L),
  (3, 1548293081490L),
  (4, 1548293081490L),
  (5, 1548293081490L),
  (6, 1548293081491L),
  (7, 1548293081491L)
)
```
<aside class="notes"><ul>
<li>Same as pure and collections.</li>
<li>terminates when one of the stream in combination ends.</li>
</ul>
</aside></script></section></section><section ><section data-markdown><script type="text/template">### File IO
Imports
```scala
interp.load.ivy("co.fs2" %% "fs2-core" % "1.0.2")
interp.load.ivy("co.fs2" %% "fs2-io" % "1.0.2")

import cats.effect.{ContextShift, IO, Timer}
import fs2._
import java.nio.file.Paths
import java.util.concurrent.Executors
import scala.concurrent.ExecutionContext

implicit val cs: ContextShift[IO] = IO.contextShift(scala.concurrent.ExecutionContext.Implicits.global)
implicit val timer: Timer[IO] = IO.timer(scala.concurrent.ExecutionContext.Implicits.global)

val blockingExecutionContext = ExecutionContext.fromExecutorService(Executors.newFixedThreadPool(2))
```</script></section><section data-markdown><script type="text/template">### File IO
Raw bytes

```scala
val src = io.file.readAll[IO](java.nio.file.Paths.get("fahrenheit.txt"), blockingExecutionContext, 16)
// src: Stream[IO, Byte] = Stream(..)

src.compile.toVector.unsafeRunSync
//res7: Vector[Byte] = Vector(
//  47,
//  47,
//  32,
//  116,
...
```</script></section><section data-markdown><script type="text/template">### File IO
Stream transformations
```scala
text.utf8Decode
// res8: Stream[Nothing, Byte] => Stream[Nothing, String] = fs2.text$$$Lambda$1929/18862762@a84ea8

src.through(text.utf8Decode)
// res9: Stream[IO[x], String] = Stream(..)

res9.compile.toVector.unsafeRunSync
// res10: Vector[String] = Vector(
//  "// this file con",
//  "tains a list of ",
//  "temperatures in ",
//  "degrees fahrenhe",
//  """it
// 18.0
// 17.9
// 25""",
```
<aside class="notes"><ul>
<li>text.ut8Decode, text.lines are of type:  &#39;Pipe[F{_], -I, +O]&#39;</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### Control flow
'through'
```scala
def fahrenheitToCelsius(f: Double): Double = (f - 32.0) * (5.0/9.0)
// defined function fahrenheitToCelsius

src.through(text.utf8Decode).through(text.lines).map(_.toDouble).map(fahrenheitToCelsius)
// res12: Stream[IO[x], Double] = Stream(..)

res12.compile.toVector.unsafeRunSync
// java.lang.NumberFormatException: For input string: "// this file contains a list of temperatures in degrees fahrenheit"
//  sun.misc.FloatingDecimal.readJavaFormatString(Unknown Source)
//  sun.misc.FloatingDecimal.parseDouble(Unknown Source)
```
<aside class="notes"><ul>
<li>note the execption</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### Control flow
filters
```scala
val decoded: Stream[IO, String] = src.through(text.utf8Decode)
val lines: Stream[IO, String] = decoded.through(text.lines)
val filtered: Stream[IO, String] = lines.filter(s => !s.trim.isEmpty && !s.startsWith("//"))
val mapped: Stream[IO, String] = filtered.map(line => fahrenheitToCelsius(line.toDouble).toString)
val withNewlines: Stream[IO, String] = mapped.intersperse("\n")
val encodedBytes: Stream[IO, Byte] = withNewlines.through(text.utf8Encode)
val written: Stream[IO, Unit] = encodedBytes.through(io.file.writeAll(Paths.get("celsius2.txt"), blockingExecutionContext))
val task: IO[Unit] = written.compile.drain

task.unsafeRunSync()
blockingExecutionContext.shutdown()
```</script></section><section data-markdown><script type="text/template">### Stream type aliases

```scala    
type Pipe[F[_], -I, +O] = Stream[F, I] => Stream[F, O]
type Pipe2[F[_], -I, -I2, +O] =
	 (Stream[F, I], Stream[F, I2]) => Stream[F, O]
type Sink[F[_], -I] = Pipe[F, I, Unit]
```
<aside class="notes"><p>Do pipes compose as well as functions?
-- Ultimate way to evaluate a library is by how well it composes.</p>
<ul>
<li>&#39;through&#39; Pipe is a type alias.</li>
<li>&#39;zip&#39;  Pipe2 is a function2</li>
<li>&#39;to&#39; Sink is Pipe with output set to Unit.</li>
</ul>
</aside></script></section></section><section ><section data-markdown><script type="text/template">### Undeterministic streams
Setup
```scala
interp.load.ivy("co.fs2" %% "fs2-core" % "1.0.2")
interp.load.ivy("co.fs2" %% "fs2-io" % "1.0.2")

import cats.effect._
import fs2._
import fs2.concurrent._
import java.util.concurrent.Executors
import scala.concurrent.ExecutionContext
import scala.concurrent.duration._
import cats.effect.ContextShift

implicit val timer: Timer[IO] = IO.timer(scala.concurrent.ExecutionContext.Implicits.global)
implicit val ioContextShift: ContextShift[IO] = IO.contextShift(scala.concurrent.ExecutionContext.Implicits.global)


val ticks = Stream.awakeEvery[IO](1.second).evalMap { i => IO.delay(println("Time: " + i)) }
// ticks: Stream[IO[x], Unit] = Stream(..)

ticks.take(10).compile.drain.unsafeRunSync
// Time: 1122896920 nanoseconds
// Time: 2123038855 nanoseconds
// Time: 3125578098 nanoseconds
...

```</script></section><section data-markdown><script type="text/template">### Undeterministic streams
Add log
```scala
(Stream(1, 2, 3) ++ Stream(4, 5, 6))
// res9: Stream[Nothing, Int] = Stream(..)
res9.toVector
//res10: Vector[Int] = Vector(1, 2, 3, 4, 5, 6)

def log[A](prefix: String): Pipe[IO, A, A] = _.evalMap { a =>
    IO.delay { println(s"$prefix> $a"); a }
  }

Stream(1, 2, 3).through(log("A"))
// res12: Stream[IO, Int] = Stream(..)

res12.compile.drain.unsafeRunSync
// A> 1
// A> 2
// A> 3

```
<aside class="notes"><ul>
<li>how to monitor individual streams?</li>
<li>add log.</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### Undeterministic streams
add random delay for demo
```scala
def randomDelays[A](max: FiniteDuration): Pipe[IO,A,A] = _.evalMap { a =>
    val delay = IO.delay(scala.util.Random.nextInt(max.toMillis.toInt))
    delay.flatMap { d => Timer[IO].sleep(d.millis); IO{a}}
  }

Stream.range(1, 20).through(randomDelays(1.second))
  .through(log("Delayed")).compile.toVector.unsafeRunSync
// Delayed> 1
// Delayed> 2
// Delayed> 3
// Delayed> 4
// ...

// res17: Vector[Int] = Vector(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19)

Stream.range(1, 20).through(log("before-delay"))
  .through(randomDelays(1.second)).through(log("Delayed"))
  .compile.toVector.unsafeRunSync
// before-delay> 1
// Delayed> 1
// before-delay> 2
// Delayed> 2
// before-delay> 3
// Delayed> 3
// ...

// res18: Vector[Int] = Vector(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19)

```</script></section></section><section ><section data-markdown><script type="text/template">### Combining streams
interleved
```scala

val a = Stream.range(1, 10).through(randomDelays(1.second)).through(log("A"))
val b = Stream.range(1, 10).through(randomDelays(1.second)).through(log("B"))
val c = Stream.range(1, 10).through(randomDelays(1.second)).through(log("C"))


(a interleave b).through(log("interleaved")).compile.toVector.unsafeRunSync
// A> 1
// B> 1
// interleaved> 1
// interleaved> 1
// A> 2
// B> 2
// interleaved> 2
// interleaved> 2
// ...

//res20: Vector[Int] = Vector(1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9)

```</script></section><section data-markdown><script type="text/template">### Combining streams
merge
```scala

(a merge b).through(log("merged")).compile.toVector.unsafeRunSync
// B> 1
// merged> 1
// A> 1
// merged> 1
// A> 2
// merged> 2
// B> 2
// merged> 2
// B> 3
// merged> 3
// B> 4
// merged> 4
// A> 3
// merged> 3
// ...

// res21: Vector[Int] = Vector(1, 1, 2, 2, 3, 4, 3, 5, 4, 5, 6, 6, 7, 7, 8, 8, 9, 9)
```
<aside class="notes"><ul>
<li>notice the elements in the output are out of order.</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### Combining streams
either
```scala
(a either b).through(log("either")).compile.toVector.unsafeRunSync
// B> 1
// either> Right(1)
// A> 1
// either> Left(1)
// B> 2
// either> Right(2)
// B> 3
// either> Right(3)
// A> 2
// either> Left(2)
// A> 3
// either> Left(3)
// B> 4
// either> Right(4)
// A> 4
// either> Left(4)
// A> 5
// either> Left(5)
// A> 6
// either> Left(6)
// B> 5
// either> Right(5)
// A> 7
// either> Left(7)
// B> 6
// either> Right(6)
// A> 8
// either> Left(8)
// B> 7
// either> Right(7)
// A> 9
// either> Left(9)
// B> 8
// either> Right(8)
// B> 9
// either> Right(9)
// res23: Vector[Either[Int, Int]] = Vector(
//   Right(1),
//   Left(1),
//   Right(2),
//   Right(3),
//   Left(2),
//   Left(3),
//   Right(4),
//   Left(4),
//   Left(5),
//   Left(6),
//   Right(5),
//   Left(7),
//   Right(6),
//   Left(8),
//   Right(7),
//   Left(9),
//   Right(8),
//   Right(9)
// )


```
<aside class="notes"><ul>
<li>Like merge, but tags each output with the branch it came from.</li>
</ul>
</aside></script></section></section><section ><section data-markdown><script type="text/template">### Parallelism
```scala
  def parJoin[F2[_], O2](maxOpen: Int)(implicit ev: <:<[O, Stream[F2, O2]], ev2: <:<[F[_], F2[_]], F2: Concurrent[F2]): Stream[F2, O2] = ???
  /* Nondeterministically merges a stream of streams (outer) in to a single stream,
   * opening at most maxOpen streams at any point in time.
   */

val streams: Stream[IO, Stream[IO, Int]] = Stream(a, b, c)
// streams: Stream[IO, Stream[IO, Int]] = Stream(..)


@ streams.parJoin(3).through(log("joined")).compile.toVector.unsafeRunSync
// C> 1
// joined> 1
// B> 1
// joined> 1
// B> 2
// joined> 2
// C> 2
// joined> 2
// B> 3
// joined> 3
// B> 4
// joined> 4
// A> 1
// joined> 1
// ...


// res26: Vector[Int] = Vector(1, 1, 1, 2, 2, 3, 3, 4, 4, 2, 5, 5, 3, 6, 7, 6, 7, 4, 5, 8, 8, 9, 9, 6, 7, 8, 9)
```</script></section><section data-markdown><script type="text/template">### Signal
```scala
// Pure holder of a single value of type A that can be read in the effect F.

val x = SignallingRef[IO, Int](1)
// x: IO[SignallingRef[IO, Int]] = Bind(

// not prefered to do unsafe calls inside 
x.flatMap { x1 => x1.get}.unsafeRunSync
// res5: Int = 1

// discrete produces infinite stream of all the changes to Signal
Stream.eval(x).flatMap { x => x.discrete }.through(log("first signal")).compile.drain.unsafeToFuture
// first signal> 1

 x.flatMap {x => x.set(2)}.unsafeRunSync
// this update does not produce any effect above as we want
// because eval(x) creates a new signal


//
// starting unsafe debugging
//
val s = x.unsafeRunSync
s.discrete.through(log("second signal")).compile.drain.unsafeToFuture
// second signal> 1

// The changes can be monitored now as we are not creating new signal

s.set(2)
// res9: IO[Unit] = Bind(
res9.unsafeRunSync
// second signal> 2

s.modify(old => (old + 1, old))
// res11: IO[Int] = Bind(...
res11.unsafeRunSync
// second signal> 3
// res12: Int = 2

s.continuous.take(100).compile.toVector.unsafeRunSync
// res14: Vector[Int] = Vector(
// 3,
// 3,
// ...

s.set(6).unsafeRunSync
// second signal> 6
s.continuous.take(100).compile.toVector.unsafeRunSync
// res18: Vector[Int] = Vector(
//  6,
//  6,
//  6,
// ...

// normal non-unsafe use
Stream.eval(SignallingRef[IO, Int](0)).flatMap { s =>
     val monitor: Stream[IO, Nothing] = s.discrete.through(log("s updated")).drain
     val data: Stream[IO, Int] = Stream.range(10, 20).through(randomDelays(1.second))
     val writer: Stream[IO, Unit] = data.evalMap { d => s.set(d) }.drain
     monitor merge writer}
//res26: Stream[IO[x], Unit] = Stream(..)

res26.compile.drain.unsafeRunSync
// s updated> 0
// s updated> 10
// s updated> 11
// s updated> 12
// s updated> 13
// s updated> 14
// s updated> 15
// s updated> 16
// s updated> 17
// s updated> 18
// s updated> 19

// and hangs

Stream.eval(SignallingRef[IO, Int](0)).flatMap { s =>
     val monitor: Stream[IO, Nothing] = s.discrete.through(log("s updated")).drain
     val data: Stream[IO, Int] = Stream.range(10, 20).through(randomDelays(1.second))
     val writer: Stream[IO, Unit] = data.evalMap { d => s.set(d) }.drain
     monitor mergeHaltBoth writer}
// res19: Stream[IO[x], Unit] = Stream(..)

res19.compile.drain.unsafeRunSync
// s updated> 0
// s updated> 10
// s updated> 11
// s updated> 12
// s updated> 13
// s updated> 14
// s updated> 15
// s updated> 16
// s updated> 17
// s updated> 18
// s updated> 19

// and exits cleanly.

```
<aside class="notes"><ul>
<li>note the unsafeToFuture not Run</li>
<li>notice monitor second signal is continuuosly logging.</li>
<li>that is the reason why merge hung</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">### Queue
```scala
 Stream.eval(Queue.bounded[IO, Int](5)).flatMap { q =>
      val monitor: Stream[IO, Nothing] =  q.dequeue.through(log("dequeued")).drain
      val data: Stream[IO, Int] = Stream.range(10, 20).through(randomDelays(1.second))
      val writer: Stream[IO, Unit] = data.to(q.enqueue)
     monitor mergeHaltBoth writer}
//res21: Stream[IO[x], Unit] = Stream(..)

res21.compile.drain.unsafeRunSync
// dequeued> 10
// dequeued> 11
// dequeued> 12
// dequeued> 13
// dequeued> 14
// dequeued> 15
// dequeued> 16
// dequeued> 17
// dequeued> 18
// dequeued> 19
```
</script></section></section><section ><section data-markdown><script type="text/template">### Demo
__Word analogy__

a is to b as c is to _?

<aside class="notes"><ul>
<li>Assignment from Deep Learning specialization course.</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">#### Demo
__GloVe__

```txt    
Global Vector for Word Representation  
Reference (https://nlp.stanford.edu/projects/glove/)  
sample file: glove.6B.50d.txt  
dimension: [400000][50]  
type: [String][Double[]]
```</script></section><section data-markdown><script type="text/template">#### Demo
__Cosine similarity__


- similarity = A . B / ||A|| * ||B||  
Where,
- A = a<sub>0</sub>, a<sub>1</sub>, ... a<sub>n</sub>
- B = b<sub>0</sub>, b<sub>1</sub>, ... b<sub>n</sub>
- A . B = a<sub>0</sub> \* b<sub>0</sub> + a<sub>1</sub> \* b<sub>1</sub> + ... + a<sub>n</sub> * b<sub>n</sub>  
- ||A|| = Norm(A) =  a<sub>0</sub> \* a<sub>0</sub> + a<sub>1</sub> \* a<sub>1</sub> + ... + a<sub>n</sub> * a<sub>n</sub>  
  
<aside class="notes"><ul>
<li>applications in recommendation engines</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">#### Demo
__find word similarity__

Given word vectors e<sub>a</sub>, e<sub>b</sub>, e<sub>c</sub>, e<sub>d</sub> find d with relation:  
e<sub>a</sub> - e<sub>b</sub> ≈ e<sub>c</sub> - e<sub>d</sub> using cosine similarity
</script></section><section data-markdown><script type="text/template">#### Demo
__source__  
```scala
// https://github.com/pramalin/fs2-word-similarity/read_glove.sc
/* jar imports */
import $ivy.`co.fs2::fs2-core:1.0.2`
import $ivy.`co.fs2::fs2-io:1.0.2`

// disable REPL printing verbose IO values 
import cats.effect._

def disablePrettyPrintIO = repl.pprinter.update(repl.pprinter().copy(additionalHandlers = {
  case io: cats.effect.IO[_] => pprint.Tree.Literal("✨✨✨")
}))

disablePrettyPrintIO

def enablePrettyPrintIO = repl.pprinter.update(repl.pprinter().copy(additionalHandlers = PartialFunction.empty))

/* script starts here */
import cats.effect._
import fs2._
import java.nio.file.Paths
import java.util.concurrent.Executors
import scala.concurrent.ExecutionContext

implicit val cs: ContextShift[IO] = IO.contextShift(scala.concurrent.ExecutionContext.Implicits.global)
implicit val timer: Timer[IO] = IO.timer(scala.concurrent.ExecutionContext.Implicits.global)

val blockingEc = ExecutionContext.fromExecutorService(Executors.newFixedThreadPool(2))
val src = io.file.readAll[IO](java.nio.file.Paths.get("glove.6B.50d.txt"), blockingEc, 1024)

val lines = src.through(text.utf8Decode).through(text.lines)
val wordIndex = lines.map(_.split(" ").head).zipWithIndex
def index(word: String): Stream[IO, Long] = wordIndex.find(_._1.equals(word)).map(_._2)
// get attributes for word
def attribs(word:String) = index(word).flatMap(lines.drop(_).take(1)).map(_.split(" ").toVector).map(_.tail).map(_.map(_.toDouble)) 

// test index
index("queen").flatMap(lines.drop(_)).take(1)

// vector calc
def diffV(av: Vector[Double], bv: Vector[Double]): Vector[Double] =
  for ((a, b) <- av zip bv) yield (a - b)
def dot(av: Vector[Double], bv: Vector[Double]): Double =
  (for ((a, b) <- av zip bv) yield a * b) sum
def norm(av: Vector[Double]): Double =
  Math.sqrt((for (a <- av) yield a * a) sum)
def cosine_similarity(a: Vector[Double], b: Vector[Double]): Double =
   dot(a, b) / (norm(a) * norm(b))



// get distance between words
def dist(u: String, v: String) = (attribs(u) zip attribs(v)).map(p => cosine_similarity(p._1.toVector, p._2.toVector)) 

//dist("him", "her").compile.toVector.unsafeRunSync 
//dist("king", "queen").compile.toVector.unsafeRunSync 
//dist("man", "woman").compile.toVector.unsafeRunSync 
// ("italy", "italian", "spain"), ("india", "delhi", "japan"), ("man", "woman", "boy"), ("small", "smaller", "large")
val a = "italy"
val b = "italian"
val c = "spain"
val factor = 0.4

// word distance
def diff_word(u: String, v: String) = (attribs(u) zip attribs(v)).map(p => diffV(p._1.toVector, p._2.toVector)) 

val c_sim = for {
  w <- wordIndex
  a_b <- diff_word(a, b)
  c_x <- diff_word(c, w._1)
  sim <- Stream(cosine_similarity(a_b, c_x))
  _ <- if (sim > factor) Stream.eval(IO(println(s"$w, $sim"))) else Stream()
} yield (w._1, sim)

/*
// results
@ c_sim.take(10).compile.toVector.unsafeRunSync
(a,7), 0.40563150208976145
(an,29), 0.4252293693397883
(american,140), 0.42150345258791344
(known,225), 0.4203211204887907
(british,297), 0.42361789696212426
(french,348), 0.6347354522189068
(russian,467), 0.46762615979965744
(whose,507), 0.4229735137631385
(german,514), 0.46345247634759656
(named,564), 0.42304541430647663
@ val factor = 0.8
@ c_sim.take(1).compile.toVector.unsafeRunSync
(spanish,1141), 0.8875303721276963
res4: Vector[(String, Double)] = Vector(("spanish", 0.8875303721276963))
*/

```</script></section><section data-markdown><script type="text/template">#### Demo
__ script__  

```txt
To run, download [glove.6B.50d.txt]
(https://www.kaggle.com/watts2/glove6b50dtxt)

From Ammonite REPL.
```
```scala
@ import $file.read_glove, read_glove._

@ a
res1: String = "italy"
@ b
res2: String = "italian"
@ c
res3: String = "spain"
@ c_sim
res4: fs2.Stream[cats.effect.IO[x], (String, Double)] = Stream(..)
@ factor
res5: Double = 0.4
@ c_sim.take(10).compile.toVector.unsafeRunSync
```</script></section><section data-markdown><script type="text/template">#### Demo
__results__

```scala
@ c_sim.take(10).compile.toVector.unsafeRunSync
res1: Vector[(String, Double)] = Vector(
  ("french", 0.6347354522189068),
  ("english", 0.5219710309872815),
  ("italian", 0.7283498794430515),
  ("spanish", 0.8875303721276963),
  ("professional", 0.5020698039090873),
  ("dutch", 0.5002985942558867),
  ("mexican", 0.5790748083609243),
  ("brazilian", 0.5498009970871708),
  ("journalist", 0.528053034651764),
  ("portuguese", 0.644859697871396)

@ val factor = 0.8
@ c_sim.take(1).compile.toVector.unsafeRunSync
(spanish,1141), 0.8875303721276963
res4: Vector[(String, Double)] = Vector(("spanish", 0.8875303721276963))
```
</script></section><section data-markdown><script type="text/template">#### Demo
__other examples__  

```txt
Try with different words and factors. This can be extremely slow.

Word pair suggestions

  ("italy", "italian", "spain"),
  ("india", "delhi", "japan"),
  ("man", "woman", "boy"),
  ("small", "smaller", "large")
```
</script></section><section data-markdown><script type="text/template">#### Demo
__Streaming web App__

```txt
    To run Streaming Web App version of the script
    copy the glove file to sec/main/resources.
```
    sbt> compile
    sbt> run
    
    From a browser
    http://localhost:5000/similarity?word1=italy&word2=italian&word3=spain&factor=0.4    


    Try different words and factors.

<aside class="notes"><p>The browsers timeout unlike the REPL session, so try with lower factors first.</p>
</aside></script></section></section><section  data-markdown><script type="text/template">#### References

- Functional Programming in Scala - By Paul Chiusano and Runar Bjarnason
- [Scala with Cats Book](underscore.io)
- [FS2 Additional Resources](https://github.com/functional-streams-for-scala/fs2/wiki/Additional-Resources)
- [An IO monad for cats](https://typelevel.org/blog/2017/05/02/io-monad-for-cats.html)
- [The Making of an IO - Daniel Spiewak](https://www.youtube.com/watch?v=g_jP47HFpWA)
</script></section><section  data-markdown><script type="text/template">### The End

- Thank you!
</script></section><section  data-markdown><script type="text/template">### Questions?

 

</script></section></div>
        </div>

        <script src="./lib/js/head.min.js"></script>
        <script src="./js/reveal.js"></script>

        <script>
            function extend() {
              var target = {};
              for (var i = 0; i < arguments.length; i++) {
                var source = arguments[i];
                for (var key in source) {
                  if (source.hasOwnProperty(key)) {
                    target[key] = source[key];
                  }
                }
              }
              return target;
            }

            // Optional libraries used to extend on reveal.js
            var deps = [
              { src: './lib/js/classList.js', condition: function() { return !document.body.classList; } },
              { src: './plugin/markdown/marked.js', condition: function() { return !!document.querySelector('[data-markdown]'); } },
              { src: './plugin/markdown/markdown.js', condition: function() { return !!document.querySelector('[data-markdown]'); } },
              { src: './plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
              { src: './plugin/zoom-js/zoom.js', async: true },
              { src: './plugin/notes/notes.js', async: true },
              { src: './plugin/math/math.js', async: true }
            ];

            // default options to init reveal.js
            var defaultOptions = {
              controls: true,
              progress: true,
              history: true,
              center: true,
              transition: 'default', // none/fade/slide/convex/concave/zoom
              dependencies: deps
            };

            // options from URL query string
            var queryOptions = Reveal.getQueryHash() || {};

            var options = {"transition":"slide"};
            options = extend(defaultOptions, options, queryOptions);
        </script>


        <script>
          Reveal.initialize(options);
        </script>
    </body>
</html>
